{ 
  "train-data-paths": [
    "data/pile/shard_0/shard_0_text_document",
  ],
  "train-data-weights": [
    1.,
  ],
  "train-dataset-name": 'pile_shard0',
  "train-iters": 1000,
  "lr-decay-iters": 1000,
  "is_replay_enabled": true,
  "replay_config": {
    "enabled": true,
    # Have to specify idx filenames from original pretraining on tasks, as they contain the num iterations
    # and seen indices assuming we're using the same (non-replay) seed as during pretraining
    "replay_idx_paths_prefixes": [
      "data/pile/shard_0/shard_0_text_document_train_0_indexmap_32160ns_2048sl_1234s",
    ],
    "replay_data_weights":[
      1.00,
    ],
    "replay_idx_offsets": [
      1,
    ],
    # Fraction of samples coming from the replay buffer, between 0 and 1.
    "replay_fraction": 0.5,
    # Seed and reshuffle go hand in hand. They control whether you want to see the replay data in the same order
    # as you've seen it (done by setting reshuffle to false), and if you decide to reshuffle, what seed you should
    # use to reshuffle the seen data.
    "replay_seed": 1234,
    "replay_reshuffle_idx": false,
  },
}