{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de77d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e652e",
   "metadata": {},
   "source": [
    "# Loading Memorization Evals\n",
    "> Memorization evals are dataframes (1 per model checkpoint)\n",
    "\n",
    "> Each dataframe has two columnns: index of data and memorization score of data (accuracy between true continuation and model generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13930d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['13b', '6.7b', '2.7b', '1.3b', '800m', '350m', '125m', '19m']\n",
    "checkpoints = [23000, 43000, 63000, 83000, 103000, 123000, 143000]\n",
    "checkpoint_names = ['23m', '44m', '65m', '85m', '105m', '126m', '146m']\n",
    "filepath = '/fsx/orz/memorization-evals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ef9e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6760c972",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3814445ecd0940b19cf7586e103cb11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "13b:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39dced005ba74cf9be34cb163fa482e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "6.7b:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f28ac00cb6e4bb3be6fc922c1619fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2.7b:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281e1b2faa06442ea3322b0e5d6e4f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1.3b:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7f7edb6c284bb8b0e92ba06c0b52ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "800m:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f078eb1006424f04b95e31e7e28162bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "350m:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe00512d6b84c06b6abbe5f564c458a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "125m:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "memorization_results = {}\n",
    "for model in models:\n",
    "    \n",
    "    for checkpoint in tqdm(checkpoints, desc=model):\n",
    "        filename = os.path.join(filepath, f'memorization_{model}_{checkpoint}.hdf')\n",
    "        model_name = f'{model}-{checkpoint}'\n",
    "        try:\n",
    "            memorization_results[model_name] = pd.read_hdf(filename, key='memorization')\n",
    "        except Exception as e:\n",
    "            csv = pd.read_csv(os.path.join(filepath, f'memorization_results_{model}_{checkpoint}.csv'))\n",
    "            csv.to_hdf(filename, key='memorization', index=False)\n",
    "            memorization_results[model_name] = csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20107d37",
   "metadata": {},
   "source": [
    "# Loading Megatron Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4c7775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
     ]
    }
   ],
   "source": [
    "from megatron.data.data_utils import build_the_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf93a27c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    reading sizes...\n",
      "    reading pointers...\n",
      "    reading document index...\n",
      "    creating numpy buffer of mmap...\n",
      "    creating memory view of numpy buffer...\n",
      "    train_0:\n",
      "     no. of documents:210604984\n"
     ]
    }
   ],
   "source": [
    "dataset = build_the_dataset(\n",
    "        data_prefix = '/fsx/pile/pile_20B_tokenizer_text_document', # Replace with the path of pile document\n",
    "        name = 'train_0',\n",
    "        data_impl='mmap',\n",
    "        num_samples=131727360,\n",
    "        seq_length=2048,\n",
    "        seed=1234,\n",
    "        skip_warmup=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b9eda8",
   "metadata": {},
   "source": [
    "Memorization evals are in Pandas DataFrames. We can use Pandarallel, if required to speed up .apply operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53d14034",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandarallel\n",
      "  Downloading pandarallel-1.6.3.tar.gz (12 kB)\n",
      "Collecting dill>=0.3.1\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[K     |████████████████████████████████| 110 kB 29.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1 in /fsx/orz/memorization/lib/python3.8/site-packages (from pandarallel) (1.5.2)\n",
      "Requirement already satisfied: psutil in /fsx/orz/memorization/lib/python3.8/site-packages (from pandarallel) (5.9.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /fsx/orz/memorization/lib/python3.8/site-packages (from pandas>=1->pandarallel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /fsx/orz/memorization/lib/python3.8/site-packages (from pandas>=1->pandarallel) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /fsx/orz/memorization/lib/python3.8/site-packages (from pandas>=1->pandarallel) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /fsx/orz/memorization/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=1->pandarallel) (1.16.0)\n",
      "Building wheels for collected packages: pandarallel\n",
      "  Building wheel for pandarallel (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandarallel: filename=pandarallel-1.6.3-py3-none-any.whl size=16449 sha256=420d869fee4d17f949725f8fd5b680063135fd0601c69f976f57c811e13e68e0\n",
      "  Stored in directory: /admin/home-orz/.cache/pip/wheels/16/f5/91/d7efa7c4911ae1cf1aff825f902382eb69a1855f9987a7d17c\n",
      "Successfully built pandarallel\n",
      "Installing collected packages: dill, pandarallel\n",
      "Successfully installed dill-0.3.6 pandarallel-1.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2207d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 48 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfc4f81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
